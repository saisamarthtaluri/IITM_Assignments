{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awake\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       478\n",
      "           1       0.95      0.98      0.97       568\n",
      "           2       0.92      0.92      0.92       521\n",
      "           3       0.91      0.90      0.90       516\n",
      "           4       0.91      0.94      0.92       500\n",
      "           5       0.88      0.88      0.88       460\n",
      "           6       0.97      0.96      0.96       491\n",
      "           7       0.91      0.96      0.94       504\n",
      "           8       0.93      0.85      0.89       466\n",
      "           9       0.92      0.88      0.90       496\n",
      "\n",
      "    accuracy                           0.92      5000\n",
      "   macro avg       0.92      0.92      0.92      5000\n",
      "weighted avg       0.92      0.92      0.92      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X_train, X_test = X[:20000], X[20000:25000]\n",
    "y_train, y_test = y[:20000], y[20000:25000]\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    SVC(kernel='linear', decision_function_shape='ovr', class_weight=None)\n",
    ")\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of diagonal elements: 4623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sum_diag = np.trace(conf_matrix)\n",
    "print(\"Sum of diagonal elements:\", sum_diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awake\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Avg F1-score: 0.9723258740744225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']\n",
    "y = y.astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='poly', degree=3, decision_function_shape='ovr', class_weight='balanced', C=10))\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "weighted_avg_f1_score = report['weighted avg']['f1-score']\n",
    "print(\"Weighted Avg F1-score:\", weighted_avg_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_score(X_train, y_train, X_test, y_test):\n",
    "    model = svm.SVC(kernel='poly', C=10, gamma='auto')   \n",
    "    model.fit(X_train, y_train)    \n",
    "    predictions = model.predict(X_test)  \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracy = compute_score(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28888888888888886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_score(X_train, y_train, X_test, y_test):\n",
    "    model = svm.SVC(kernel='sigmoid', C=25, gamma='auto')\n",
    "    model.fit(X_train, y_train)    \n",
    "    predictions = model.predict(X_test)    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracy = compute_score(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[iris.target != 0] \n",
    "y = iris.target[iris.target != 0] \n",
    "\n",
    "pipeline = make_pipeline(MinMaxScaler(), svm.SVC())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "print(f'Precision: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
